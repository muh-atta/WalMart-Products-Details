name: Run Walmart Scraper

permissions:
  contents: write  # ✅ Required for pushing changes

on:
  workflow_dispatch:
  schedule:
    - cron: '*/5 * * * *'  # ✅ Run every 5 minutes

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false  # ⛔️ We use PAT manually

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libx11-dev \
            libx11-xcb1 \
            libxcomposite1 \
            libxcursor1 \
            libxdamage1 \
            libxi6 \
            libxtst6 \
            libnss3 \
            libatk-bridge2.0-0 \
            libgtk-3-0 \
            libdrm2 \
            libgbm1 \
            libasound2t64

      - name: Install Node.js dependencies
        run: npm install

      - name: Install Chromium for Puppeteer
        run: npx puppeteer browsers install chrome

      - name: Run scraper script
        run: node WalmartTrigerData.js

      - name: Commit and push changes
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add walmart-data.csv walmart-data.json
          git commit -m "Auto update scraped data - $(date)" || echo "No changes to commit"
         git remote set-url origin https://github-actions:${{ secrets.ACTIONS_PAT }}@github.com/mirzahanzla/Project-Product-Details.git
          git push origin HEAD:main
        env:
          ACTIONS_PAT: ${{ secrets.ACTIONS_PAT }}
